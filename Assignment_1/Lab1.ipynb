{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor: Vineet Madan\\nPurpose: Lab Assignment 1 of CS529\\nDate: 31 August 2019\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Vineet Madan\n",
    "Purpose: Lab Assignment 1 of CS529\n",
    "Date: 31 August 2019\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the datasets (in csv) as pd dataframes\n",
    "movies_df = pd.read_csv(\"./ml-latest-small/movies.csv\")\n",
    "ratings_df = pd.read_csv(\"./ml-latest-small/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the head of the movies dataset\n",
    "movies_df.head\n",
    "\n",
    "#give new id(s) to the movies...maps old ids to new ones\n",
    "new_movie_ids = {}\n",
    "\n",
    "for index, row in movies_df.iterrows():\n",
    "    new_movie_ids[int(row['movieId'])] = index\n",
    "\n",
    "# function to get new movie id\n",
    "def get_new_movie_id(old_movie_id):\n",
    "    return new_movie_ids[old_movie_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "5            1       70     3.0   964982400\n",
       "6            1      101     5.0   964980868\n",
       "7            1      110     4.0   964982176\n",
       "8            1      151     5.0   964984041\n",
       "9            1      157     5.0   964984100\n",
       "10           1      163     5.0   964983650\n",
       "11           1      216     5.0   964981208\n",
       "12           1      223     3.0   964980985\n",
       "13           1      231     5.0   964981179\n",
       "14           1      235     4.0   964980908\n",
       "15           1      260     5.0   964981680\n",
       "16           1      296     3.0   964982967\n",
       "17           1      316     3.0   964982310\n",
       "18           1      333     5.0   964981179\n",
       "19           1      349     4.0   964982563\n",
       "20           1      356     4.0   964980962\n",
       "21           1      362     5.0   964982588\n",
       "22           1      367     4.0   964981710\n",
       "23           1      423     3.0   964982363\n",
       "24           1      441     4.0   964980868\n",
       "25           1      457     5.0   964981909\n",
       "26           1      480     4.0   964982346\n",
       "27           1      500     3.0   964981208\n",
       "28           1      527     5.0   964984002\n",
       "29           1      543     4.0   964981179\n",
       "...        ...      ...     ...         ...\n",
       "100806     610   150401     3.0  1479543210\n",
       "100807     610   152077     4.0  1493845817\n",
       "100808     610   152081     4.0  1493846503\n",
       "100809     610   152372     3.5  1493848841\n",
       "100810     610   155064     3.5  1493848456\n",
       "100811     610   156371     5.0  1479542831\n",
       "100812     610   156726     4.5  1493848444\n",
       "100813     610   157296     4.0  1493846563\n",
       "100814     610   158238     5.0  1479545219\n",
       "100815     610   158721     3.5  1479542491\n",
       "100816     610   158872     3.5  1493848024\n",
       "100817     610   158956     3.0  1493848947\n",
       "100818     610   159093     3.0  1493847704\n",
       "100819     610   160080     3.0  1493848031\n",
       "100820     610   160341     2.5  1479545749\n",
       "100821     610   160527     4.5  1479544998\n",
       "100822     610   160571     3.0  1493848537\n",
       "100823     610   160836     3.0  1493844794\n",
       "100824     610   161582     4.0  1493847759\n",
       "100825     610   161634     4.0  1493848362\n",
       "100826     610   162350     3.5  1493849971\n",
       "100827     610   163937     3.5  1493848789\n",
       "100828     610   163981     3.5  1493850155\n",
       "100829     610   164179     5.0  1493845631\n",
       "100830     610   166528     4.0  1493879365\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the head of the ratings dataset\n",
    "ratings_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1. Plot  a  histogram  to  show  the  variation  of  the  number  of  user  ratings  per movie  in  the  dataset\n",
    "\"\"\"\n",
    "#number of ratings per movie\n",
    "number_of_ratings_per_movie_dict = {}\n",
    "for index, row in movies_df.iterrows():\n",
    "    number_of_ratings_per_movie_dict[row['movieId']] = 0\n",
    "for index, row in ratings_df.iterrows():\n",
    "    number_of_ratings_per_movie_dict[row['movieId']]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get name of a movie with a movie_id\n",
    "def get_movie_name_by_id(movie_id):\n",
    "    for index, row in movies_df.iterrows():\n",
    "        if row['movieId']==movie_id:\n",
    "            return row['title']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movies = len(movies_df)\n",
    "num_users = 610"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number_of_ratings_per_movie_dict has the [movie_id, ratings per movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 215,\n",
       " 2: 110,\n",
       " 3: 52,\n",
       " 4: 7,\n",
       " 5: 49,\n",
       " 6: 102,\n",
       " 7: 54,\n",
       " 8: 8,\n",
       " 9: 16,\n",
       " 10: 132,\n",
       " 11: 70,\n",
       " 12: 19,\n",
       " 13: 8,\n",
       " 14: 18,\n",
       " 15: 13,\n",
       " 16: 82,\n",
       " 17: 67,\n",
       " 18: 20,\n",
       " 19: 88,\n",
       " 20: 15,\n",
       " 21: 89,\n",
       " 22: 36,\n",
       " 23: 16,\n",
       " 24: 28,\n",
       " 25: 76,\n",
       " 26: 13,\n",
       " 27: 9,\n",
       " 28: 11,\n",
       " 29: 38,\n",
       " 30: 3,\n",
       " 31: 38,\n",
       " 32: 177,\n",
       " 34: 128,\n",
       " 36: 67,\n",
       " 38: 4,\n",
       " 39: 104,\n",
       " 40: 2,\n",
       " 41: 15,\n",
       " 42: 7,\n",
       " 43: 8,\n",
       " 44: 46,\n",
       " 45: 32,\n",
       " 46: 15,\n",
       " 47: 203,\n",
       " 48: 68,\n",
       " 49: 1,\n",
       " 50: 204,\n",
       " 52: 28,\n",
       " 53: 2,\n",
       " 54: 3,\n",
       " 55: 1,\n",
       " 57: 8,\n",
       " 58: 37,\n",
       " 60: 34,\n",
       " 61: 6,\n",
       " 62: 80,\n",
       " 63: 7,\n",
       " 64: 5,\n",
       " 65: 31,\n",
       " 66: 9,\n",
       " 68: 5,\n",
       " 69: 20,\n",
       " 70: 55,\n",
       " 71: 5,\n",
       " 72: 7,\n",
       " 73: 13,\n",
       " 74: 8,\n",
       " 75: 5,\n",
       " 76: 15,\n",
       " 77: 1,\n",
       " 78: 3,\n",
       " 79: 17,\n",
       " 80: 2,\n",
       " 81: 14,\n",
       " 82: 8,\n",
       " 83: 1,\n",
       " 85: 7,\n",
       " 86: 15,\n",
       " 87: 7,\n",
       " 88: 16,\n",
       " 89: 10,\n",
       " 92: 8,\n",
       " 93: 9,\n",
       " 94: 10,\n",
       " 95: 84,\n",
       " 96: 1,\n",
       " 97: 10,\n",
       " 99: 2,\n",
       " 100: 14,\n",
       " 101: 23,\n",
       " 102: 5,\n",
       " 103: 3,\n",
       " 104: 99,\n",
       " 105: 23,\n",
       " 106: 1,\n",
       " 107: 26,\n",
       " 108: 1,\n",
       " 110: 237,\n",
       " 111: 104,\n",
       " 112: 46,\n",
       " 113: 3,\n",
       " 116: 5,\n",
       " 117: 1,\n",
       " 118: 2,\n",
       " 119: 2,\n",
       " 121: 2,\n",
       " 122: 16,\n",
       " 123: 4,\n",
       " 125: 12,\n",
       " 126: 7,\n",
       " 128: 1,\n",
       " 129: 1,\n",
       " 132: 6,\n",
       " 135: 31,\n",
       " 137: 1,\n",
       " 140: 16,\n",
       " 141: 86,\n",
       " 144: 12,\n",
       " 145: 51,\n",
       " 146: 3,\n",
       " 147: 15,\n",
       " 148: 1,\n",
       " 149: 1,\n",
       " 150: 201,\n",
       " 151: 44,\n",
       " 152: 2,\n",
       " 153: 137,\n",
       " 154: 12,\n",
       " 155: 6,\n",
       " 156: 3,\n",
       " 157: 11,\n",
       " 158: 62,\n",
       " 159: 14,\n",
       " 160: 57,\n",
       " 161: 103,\n",
       " 162: 17,\n",
       " 163: 66,\n",
       " 164: 14,\n",
       " 165: 144,\n",
       " 166: 3,\n",
       " 168: 54,\n",
       " 169: 10,\n",
       " 170: 35,\n",
       " 171: 6,\n",
       " 172: 53,\n",
       " 173: 62,\n",
       " 174: 10,\n",
       " 175: 20,\n",
       " 176: 13,\n",
       " 177: 8,\n",
       " 178: 1,\n",
       " 179: 2,\n",
       " 180: 36,\n",
       " 181: 17,\n",
       " 183: 2,\n",
       " 184: 2,\n",
       " 185: 112,\n",
       " 186: 48,\n",
       " 187: 4,\n",
       " 188: 12,\n",
       " 189: 1,\n",
       " 190: 5,\n",
       " 191: 6,\n",
       " 193: 35,\n",
       " 194: 18,\n",
       " 195: 10,\n",
       " 196: 45,\n",
       " 198: 28,\n",
       " 199: 4,\n",
       " 201: 1,\n",
       " 202: 1,\n",
       " 203: 22,\n",
       " 204: 30,\n",
       " 205: 9,\n",
       " 206: 2,\n",
       " 207: 21,\n",
       " 208: 115,\n",
       " 209: 3,\n",
       " 210: 4,\n",
       " 211: 2,\n",
       " 212: 3,\n",
       " 213: 6,\n",
       " 214: 2,\n",
       " 215: 24,\n",
       " 216: 49,\n",
       " 217: 6,\n",
       " 218: 14,\n",
       " 219: 1,\n",
       " 220: 1,\n",
       " 222: 16,\n",
       " 223: 104,\n",
       " 224: 40,\n",
       " 225: 52,\n",
       " 227: 22,\n",
       " 228: 3,\n",
       " 229: 7,\n",
       " 230: 24,\n",
       " 231: 133,\n",
       " 232: 14,\n",
       " 233: 12,\n",
       " 234: 17,\n",
       " 235: 70,\n",
       " 236: 45,\n",
       " 237: 22,\n",
       " 238: 2,\n",
       " 239: 17,\n",
       " 240: 4,\n",
       " 241: 1,\n",
       " 242: 5,\n",
       " 243: 1,\n",
       " 246: 29,\n",
       " 247: 21,\n",
       " 248: 17,\n",
       " 249: 18,\n",
       " 250: 6,\n",
       " 251: 3,\n",
       " 252: 43,\n",
       " 253: 109,\n",
       " 254: 1,\n",
       " 255: 7,\n",
       " 256: 35,\n",
       " 257: 14,\n",
       " 258: 10,\n",
       " 259: 5,\n",
       " 260: 251,\n",
       " 261: 42,\n",
       " 262: 21,\n",
       " 263: 1,\n",
       " 265: 33,\n",
       " 266: 68,\n",
       " 267: 17,\n",
       " 269: 2,\n",
       " 270: 5,\n",
       " 271: 4,\n",
       " 272: 31,\n",
       " 273: 28,\n",
       " 274: 7,\n",
       " 275: 6,\n",
       " 276: 22,\n",
       " 277: 38,\n",
       " 278: 2,\n",
       " 279: 2,\n",
       " 280: 13,\n",
       " 281: 14,\n",
       " 282: 40,\n",
       " 283: 3,\n",
       " 284: 1,\n",
       " 285: 1,\n",
       " 287: 1,\n",
       " 288: 92,\n",
       " 289: 8,\n",
       " 290: 14,\n",
       " 291: 3,\n",
       " 292: 101,\n",
       " 293: 133,\n",
       " 294: 2,\n",
       " 295: 1,\n",
       " 296: 307,\n",
       " 298: 1,\n",
       " 299: 4,\n",
       " 300: 81,\n",
       " 301: 1,\n",
       " 302: 5,\n",
       " 303: 32,\n",
       " 304: 3,\n",
       " 305: 9,\n",
       " 306: 16,\n",
       " 307: 24,\n",
       " 308: 20,\n",
       " 310: 1,\n",
       " 311: 1,\n",
       " 312: 9,\n",
       " 313: 3,\n",
       " 314: 16,\n",
       " 315: 38,\n",
       " 316: 140,\n",
       " 317: 81,\n",
       " 318: 317,\n",
       " 319: 20,\n",
       " 320: 1,\n",
       " 321: 2,\n",
       " 322: 10,\n",
       " 324: 1,\n",
       " 325: 7,\n",
       " 326: 3,\n",
       " 327: 34,\n",
       " 328: 10,\n",
       " 329: 108,\n",
       " 330: 6,\n",
       " 331: 2,\n",
       " 332: 12,\n",
       " 333: 50,\n",
       " 334: 5,\n",
       " 335: 2,\n",
       " 336: 1,\n",
       " 337: 77,\n",
       " 338: 19,\n",
       " 339: 98,\n",
       " 340: 5,\n",
       " 341: 2,\n",
       " 342: 33,\n",
       " 343: 5,\n",
       " 344: 161,\n",
       " 345: 36,\n",
       " 346: 6,\n",
       " 347: 6,\n",
       " 348: 30,\n",
       " 349: 110,\n",
       " 350: 57,\n",
       " 351: 17,\n",
       " 352: 2,\n",
       " 353: 64,\n",
       " 354: 6,\n",
       " 355: 42,\n",
       " 356: 329,\n",
       " 357: 103,\n",
       " 358: 9,\n",
       " 359: 1,\n",
       " 360: 8,\n",
       " 361: 17,\n",
       " 362: 34,\n",
       " 363: 2,\n",
       " 364: 172,\n",
       " 365: 4,\n",
       " 366: 12,\n",
       " 367: 157,\n",
       " 368: 74,\n",
       " 369: 2,\n",
       " 370: 58,\n",
       " 371: 21,\n",
       " 372: 21,\n",
       " 373: 11,\n",
       " 374: 25,\n",
       " 376: 40,\n",
       " 377: 171,\n",
       " 378: 7,\n",
       " 379: 21,\n",
       " 380: 178,\n",
       " 381: 11,\n",
       " 382: 16,\n",
       " 383: 21,\n",
       " 384: 2,\n",
       " 385: 1,\n",
       " 386: 1,\n",
       " 387: 4,\n",
       " 388: 2,\n",
       " 389: 2,\n",
       " 390: 5,\n",
       " 391: 1,\n",
       " 393: 10,\n",
       " 405: 12,\n",
       " 406: 1,\n",
       " 407: 8,\n",
       " 408: 2,\n",
       " 409: 1,\n",
       " 410: 84,\n",
       " 412: 15,\n",
       " 413: 26,\n",
       " 414: 6,\n",
       " 415: 16,\n",
       " 416: 8,\n",
       " 417: 13,\n",
       " 418: 2,\n",
       " 419: 20,\n",
       " 420: 59,\n",
       " 421: 12,\n",
       " 422: 5,\n",
       " 423: 10,\n",
       " 424: 3,\n",
       " 425: 2,\n",
       " 426: 7,\n",
       " 427: 12,\n",
       " 428: 18,\n",
       " 429: 6,\n",
       " 430: 2,\n",
       " 431: 42,\n",
       " 432: 55,\n",
       " 433: 8,\n",
       " 434: 101,\n",
       " 435: 63,\n",
       " 436: 7,\n",
       " 437: 9,\n",
       " 438: 7,\n",
       " 440: 76,\n",
       " 441: 42,\n",
       " 442: 81,\n",
       " 444: 6,\n",
       " 445: 12,\n",
       " 446: 9,\n",
       " 448: 8,\n",
       " 449: 1,\n",
       " 450: 7,\n",
       " 451: 1,\n",
       " 452: 3,\n",
       " 453: 5,\n",
       " 454: 101,\n",
       " 455: 37,\n",
       " 456: 4,\n",
       " 457: 190,\n",
       " 458: 5,\n",
       " 459: 6,\n",
       " 460: 3,\n",
       " 461: 4,\n",
       " 464: 10,\n",
       " 466: 60,\n",
       " 467: 1,\n",
       " 468: 22,\n",
       " 469: 5,\n",
       " 470: 1,\n",
       " 471: 40,\n",
       " 472: 6,\n",
       " 473: 7,\n",
       " 474: 70,\n",
       " 475: 25,\n",
       " 476: 1,\n",
       " 477: 17,\n",
       " 478: 1,\n",
       " 479: 4,\n",
       " 480: 238,\n",
       " 481: 19,\n",
       " 482: 8,\n",
       " 484: 2,\n",
       " 485: 53,\n",
       " 486: 3,\n",
       " 487: 4,\n",
       " 488: 1,\n",
       " 489: 11,\n",
       " 490: 12,\n",
       " 491: 17,\n",
       " 492: 14,\n",
       " 493: 12,\n",
       " 494: 41,\n",
       " 495: 1,\n",
       " 496: 1,\n",
       " 497: 43,\n",
       " 499: 2,\n",
       " 500: 144,\n",
       " 501: 6,\n",
       " 502: 15,\n",
       " 504: 2,\n",
       " 505: 7,\n",
       " 506: 2,\n",
       " 507: 13,\n",
       " 508: 66,\n",
       " 509: 61,\n",
       " 510: 1,\n",
       " 511: 2,\n",
       " 512: 4,\n",
       " 513: 4,\n",
       " 514: 18,\n",
       " 515: 24,\n",
       " 516: 18,\n",
       " 517: 9,\n",
       " 518: 4,\n",
       " 519: 21,\n",
       " 520: 69,\n",
       " 521: 3,\n",
       " 522: 7,\n",
       " 523: 4,\n",
       " 524: 34,\n",
       " 526: 1,\n",
       " 527: 220,\n",
       " 528: 3,\n",
       " 529: 40,\n",
       " 531: 24,\n",
       " 532: 16,\n",
       " 533: 18,\n",
       " 534: 14,\n",
       " 535: 15,\n",
       " 536: 3,\n",
       " 537: 12,\n",
       " 538: 12,\n",
       " 539: 106,\n",
       " 540: 18,\n",
       " 541: 124,\n",
       " 542: 14,\n",
       " 543: 41,\n",
       " 544: 8,\n",
       " 546: 21,\n",
       " 547: 2,\n",
       " 548: 6,\n",
       " 549: 2,\n",
       " 550: 5,\n",
       " 551: 93,\n",
       " 552: 61,\n",
       " 553: 65,\n",
       " 555: 65,\n",
       " 556: 6,\n",
       " 558: 8,\n",
       " 562: 23,\n",
       " 563: 1,\n",
       " 564: 2,\n",
       " 567: 3,\n",
       " 568: 2,\n",
       " 569: 6,\n",
       " 573: 1,\n",
       " 574: 4,\n",
       " 575: 16,\n",
       " 577: 4,\n",
       " 579: 1,\n",
       " 580: 5,\n",
       " 581: 4,\n",
       " 583: 1,\n",
       " 585: 36,\n",
       " 586: 116,\n",
       " 587: 115,\n",
       " 588: 183,\n",
       " 589: 224,\n",
       " 590: 164,\n",
       " 592: 189,\n",
       " 593: 279,\n",
       " 594: 77,\n",
       " 595: 146,\n",
       " 596: 60,\n",
       " 597: 135,\n",
       " 599: 11,\n",
       " 600: 1,\n",
       " 602: 1,\n",
       " 605: 10,\n",
       " 606: 4,\n",
       " 608: 181,\n",
       " 609: 14,\n",
       " 610: 33,\n",
       " 611: 6,\n",
       " 612: 6,\n",
       " 613: 8,\n",
       " 615: 1,\n",
       " 616: 45,\n",
       " 617: 3,\n",
       " 618: 1,\n",
       " 619: 5,\n",
       " 626: 1,\n",
       " 627: 6,\n",
       " 628: 35,\n",
       " 631: 11,\n",
       " 632: 1,\n",
       " 633: 1,\n",
       " 634: 4,\n",
       " 635: 2,\n",
       " 636: 1,\n",
       " 637: 33,\n",
       " 638: 1,\n",
       " 639: 4,\n",
       " 640: 11,\n",
       " 645: 2,\n",
       " 647: 29,\n",
       " 648: 162,\n",
       " 649: 1,\n",
       " 650: 4,\n",
       " 653: 65,\n",
       " 656: 5,\n",
       " 661: 49,\n",
       " 662: 7,\n",
       " 663: 12,\n",
       " 665: 3,\n",
       " 667: 8,\n",
       " 668: 2,\n",
       " 670: 2,\n",
       " 671: 36,\n",
       " 673: 53,\n",
       " 674: 9,\n",
       " 678: 9,\n",
       " 679: 1,\n",
       " 680: 4,\n",
       " 685: 2,\n",
       " 688: 9,\n",
       " 691: 3,\n",
       " 692: 4,\n",
       " 694: 11,\n",
       " 695: 2,\n",
       " 697: 5,\n",
       " 698: 1,\n",
       " 700: 7,\n",
       " 703: 2,\n",
       " 704: 7,\n",
       " 706: 1,\n",
       " 707: 21,\n",
       " 708: 58,\n",
       " 709: 11,\n",
       " 710: 8,\n",
       " 711: 10,\n",
       " 714: 15,\n",
       " 715: 3,\n",
       " 718: 4,\n",
       " 719: 35,\n",
       " 720: 27,\n",
       " 722: 1,\n",
       " 724: 31,\n",
       " 725: 5,\n",
       " 726: 1,\n",
       " 728: 10,\n",
       " 731: 3,\n",
       " 733: 121,\n",
       " 735: 7,\n",
       " 736: 123,\n",
       " 737: 20,\n",
       " 741: 27,\n",
       " 742: 11,\n",
       " 743: 29,\n",
       " 745: 48,\n",
       " 747: 3,\n",
       " 748: 22,\n",
       " 750: 97,\n",
       " 757: 1,\n",
       " 759: 2,\n",
       " 760: 2,\n",
       " 761: 19,\n",
       " 762: 41,\n",
       " 764: 2,\n",
       " 765: 19,\n",
       " 766: 4,\n",
       " 773: 1,\n",
       " 775: 1,\n",
       " 778: 102,\n",
       " 779: 2,\n",
       " 780: 202,\n",
       " 781: 7,\n",
       " 782: 8,\n",
       " 783: 47,\n",
       " 784: 54,\n",
       " 785: 42,\n",
       " 786: 64,\n",
       " 788: 82,\n",
       " 790: 1,\n",
       " 791: 1,\n",
       " 795: 2,\n",
       " 798: 12,\n",
       " 799: 23,\n",
       " 800: 19,\n",
       " 801: 11,\n",
       " 802: 46,\n",
       " 803: 1,\n",
       " 804: 8,\n",
       " 805: 35,\n",
       " 806: 1,\n",
       " 808: 2,\n",
       " 809: 9,\n",
       " 810: 12,\n",
       " 813: 5,\n",
       " 818: 10,\n",
       " 823: 1,\n",
       " 824: 1,\n",
       " 828: 6,\n",
       " 829: 9,\n",
       " 830: 21,\n",
       " 832: 37,\n",
       " 833: 6,\n",
       " 835: 3,\n",
       " 836: 17,\n",
       " 837: 33,\n",
       " 838: 30,\n",
       " 839: 15,\n",
       " 840: 4,\n",
       " 841: 2,\n",
       " 842: 12,\n",
       " 848: 7,\n",
       " 849: 44,\n",
       " 851: 6,\n",
       " 852: 43,\n",
       " 858: 192,\n",
       " 861: 9,\n",
       " 866: 23,\n",
       " 867: 2,\n",
       " 869: 3,\n",
       " 870: 2,\n",
       " 875: 1,\n",
       " 876: 1,\n",
       " 879: 4,\n",
       " 880: 27,\n",
       " 881: 5,\n",
       " 882: 1,\n",
       " 885: 2,\n",
       " 886: 6,\n",
       " 888: 3,\n",
       " 889: 1,\n",
       " 891: 5,\n",
       " 892: 13,\n",
       " 893: 3,\n",
       " 896: 2,\n",
       " 897: 2,\n",
       " 898: 29,\n",
       " 899: 47,\n",
       " 900: 12,\n",
       " 901: 7,\n",
       " 902: 36,\n",
       " 903: 60,\n",
       " 904: 84,\n",
       " 905: 14,\n",
       " 906: 7,\n",
       " 907: 2,\n",
       " 908: 57,\n",
       " 909: 27,\n",
       " 910: 50,\n",
       " 911: 13,\n",
       " 912: 100,\n",
       " 913: 44,\n",
       " 914: 35,\n",
       " 915: 30,\n",
       " 916: 26,\n",
       " 917: 2,\n",
       " 918: 10,\n",
       " 919: 92,\n",
       " 920: 45,\n",
       " 921: 9,\n",
       " 922: 27,\n",
       " 923: 69,\n",
       " 924: 109,\n",
       " 926: 24,\n",
       " 927: 3,\n",
       " 928: 18,\n",
       " 929: 1,\n",
       " 930: 20,\n",
       " 931: 9,\n",
       " 932: 8,\n",
       " 933: 23,\n",
       " 934: 12,\n",
       " 935: 3,\n",
       " 936: 6,\n",
       " 937: 2,\n",
       " 938: 6,\n",
       " 940: 8,\n",
       " 941: 2,\n",
       " 942: 6,\n",
       " 943: 7,\n",
       " 944: 3,\n",
       " 945: 7,\n",
       " 946: 3,\n",
       " 947: 4,\n",
       " 948: 6,\n",
       " 949: 6,\n",
       " 950: 7,\n",
       " 951: 14,\n",
       " 952: 12,\n",
       " 953: 58,\n",
       " 954: 18,\n",
       " 955: 18,\n",
       " 956: 1,\n",
       " 959: 1,\n",
       " 961: 1,\n",
       " 963: 1,\n",
       " 965: 11,\n",
       " 968: 28,\n",
       " 969: 34,\n",
       " 970: 1,\n",
       " 971: 10,\n",
       " 973: 5,\n",
       " 976: 1,\n",
       " 979: 1,\n",
       " 981: 2,\n",
       " 982: 1,\n",
       " 984: 2,\n",
       " 986: 13,\n",
       " 987: 1,\n",
       " 988: 2,\n",
       " 990: 5,\n",
       " 991: 11,\n",
       " 993: 1,\n",
       " 994: 11,\n",
       " 996: 13,\n",
       " 998: 3,\n",
       " 999: 12,\n",
       " 1003: 3,\n",
       " 1004: 6,\n",
       " 1005: 8,\n",
       " 1006: 5,\n",
       " 1007: 10,\n",
       " 1008: 1,\n",
       " 1009: 9,\n",
       " 1010: 9,\n",
       " 1011: 8,\n",
       " 1012: 9,\n",
       " 1013: 12,\n",
       " 1014: 5,\n",
       " 1015: 20,\n",
       " 1016: 5,\n",
       " 1017: 10,\n",
       " 1018: 6,\n",
       " 1019: 17,\n",
       " 1020: 37,\n",
       " 1021: 27,\n",
       " 1022: 42,\n",
       " 1023: 13,\n",
       " 1024: 6,\n",
       " 1025: 25,\n",
       " 1027: 28,\n",
       " 1028: 71,\n",
       " 1029: 35,\n",
       " 1030: 15,\n",
       " 1031: 24,\n",
       " 1032: 40,\n",
       " 1033: 20,\n",
       " 1034: 5,\n",
       " 1035: 64,\n",
       " 1036: 145,\n",
       " 1037: 24,\n",
       " 1040: 1,\n",
       " 1041: 11,\n",
       " 1042: 42,\n",
       " 1043: 5,\n",
       " 1046: 4,\n",
       " 1047: 33,\n",
       " 1049: 21,\n",
       " 1050: 5,\n",
       " 1051: 3,\n",
       " 1053: 1,\n",
       " 1054: 1,\n",
       " 1055: 2,\n",
       " 1056: 7,\n",
       " 1057: 15,\n",
       " 1059: 36,\n",
       " 1060: 36,\n",
       " 1061: 29,\n",
       " 1064: 13,\n",
       " 1066: 4,\n",
       " 1068: 1,\n",
       " 1073: 119,\n",
       " 1076: 0,\n",
       " 1077: 28,\n",
       " 1078: 11,\n",
       " 1079: 71,\n",
       " 1080: 89,\n",
       " 1081: 12,\n",
       " 1082: 6,\n",
       " 1083: 6,\n",
       " 1084: 35,\n",
       " 1085: 2,\n",
       " 1086: 25,\n",
       " 1088: 42,\n",
       " 1089: 131,\n",
       " 1090: 63,\n",
       " 1091: 21,\n",
       " 1092: 47,\n",
       " 1093: 37,\n",
       " 1094: 42,\n",
       " 1095: 15,\n",
       " 1096: 10,\n",
       " 1097: 122,\n",
       " 1099: 4,\n",
       " 1100: 19,\n",
       " 1101: 83,\n",
       " 1103: 15,\n",
       " 1104: 20,\n",
       " 1105: 3,\n",
       " 1107: 2,\n",
       " 1111: 4,\n",
       " 1112: 2,\n",
       " 1114: 1,\n",
       " 1116: 1,\n",
       " 1117: 1,\n",
       " 1119: 1,\n",
       " 1120: 27,\n",
       " 1121: 1,\n",
       " 1123: 2,\n",
       " 1124: 13,\n",
       " 1125: 24,\n",
       " 1126: 6,\n",
       " 1127: 62,\n",
       " 1128: 5,\n",
       " 1129: 39,\n",
       " 1130: 5,\n",
       " 1131: 11,\n",
       " 1132: 8,\n",
       " 1135: 13,\n",
       " 1136: 136,\n",
       " 1137: 1,\n",
       " 1140: 1,\n",
       " 1144: 1,\n",
       " 1147: 10,\n",
       " 1148: 56,\n",
       " 1150: 3,\n",
       " 1151: 2,\n",
       " 1156: 1,\n",
       " 1161: 3,\n",
       " 1162: 1,\n",
       " 1163: 1,\n",
       " 1167: 2,\n",
       " 1170: 2,\n",
       " 1171: 17,\n",
       " 1172: 34,\n",
       " 1173: 11,\n",
       " 1175: 21,\n",
       " 1176: 3,\n",
       " 1177: 6,\n",
       " 1178: 12,\n",
       " 1179: 27,\n",
       " 1180: 1,\n",
       " 1183: 45,\n",
       " 1184: 7,\n",
       " 1185: 10,\n",
       " 1186: 23,\n",
       " 1187: 5,\n",
       " 1188: 22,\n",
       " 1189: 11,\n",
       " 1190: 6,\n",
       " 1191: 6,\n",
       " 1192: 5,\n",
       " 1193: 133,\n",
       " 1194: 11,\n",
       " 1196: 211,\n",
       " 1197: 142,\n",
       " 1198: 200,\n",
       " 1199: 59,\n",
       " 1200: 126,\n",
       " 1201: 72,\n",
       " 1202: 7,\n",
       " 1203: 57,\n",
       " 1204: 45,\n",
       " 1206: 120,\n",
       " 1207: 58,\n",
       " 1208: 107,\n",
       " 1209: 18,\n",
       " 1210: 196,\n",
       " 1211: 13,\n",
       " 1212: 24,\n",
       " 1213: 126,\n",
       " 1214: 146,\n",
       " 1215: 51,\n",
       " 1216: 11,\n",
       " 1217: 15,\n",
       " 1218: 11,\n",
       " 1219: 83,\n",
       " 1220: 84,\n",
       " 1221: 129,\n",
       " 1222: 102,\n",
       " 1223: 28,\n",
       " 1224: 19,\n",
       " 1225: 76,\n",
       " 1226: 6,\n",
       " 1227: 16,\n",
       " 1228: 40,\n",
       " 1230: 58,\n",
       " 1231: 22,\n",
       " 1232: 8,\n",
       " 1233: 40,\n",
       " 1234: 64,\n",
       " 1235: 26,\n",
       " 1236: 3,\n",
       " 1237: 18,\n",
       " 1238: 9,\n",
       " 1240: 131,\n",
       " 1241: 10,\n",
       " 1242: 41,\n",
       " 1243: 16,\n",
       " 1244: 33,\n",
       " 1245: 20,\n",
       " 1246: 86,\n",
       " 1247: 79,\n",
       " 1248: 17,\n",
       " 1249: 35,\n",
       " 1250: 45,\n",
       " 1251: 14,\n",
       " 1252: 59,\n",
       " 1253: 25,\n",
       " 1254: 16,\n",
       " 1255: 6,\n",
       " 1256: 23,\n",
       " 1257: 27,\n",
       " 1258: 109,\n",
       " 1259: 91,\n",
       " 1260: 15,\n",
       " 1261: 34,\n",
       " 1262: 43,\n",
       " 1263: 43,\n",
       " 1264: 5,\n",
       " 1265: 143,\n",
       " 1266: 45,\n",
       " 1267: 30,\n",
       " 1268: 9,\n",
       " 1269: 29,\n",
       " 1270: 171,\n",
       " 1271: 30,\n",
       " 1272: 33,\n",
       " 1273: 11,\n",
       " 1274: 39,\n",
       " 1275: 48,\n",
       " 1276: 57,\n",
       " 1277: 12,\n",
       " 1278: 69,\n",
       " 1279: 8,\n",
       " 1280: 9,\n",
       " 1281: 15,\n",
       " 1282: 53,\n",
       " 1283: 19,\n",
       " 1284: 14,\n",
       " 1285: 41,\n",
       " 1286: 7,\n",
       " 1287: 34,\n",
       " 1288: 66,\n",
       " 1289: 11,\n",
       " 1290: 10,\n",
       " 1291: 140,\n",
       " 1292: 20,\n",
       " 1293: 27,\n",
       " 1295: 11,\n",
       " 1296: 17,\n",
       " 1297: 20,\n",
       " 1298: 23,\n",
       " 1299: 28,\n",
       " 1300: 9,\n",
       " 1301: 13,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_ratings_per_movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the new indices and then plot\n",
    "number_of_ratings_per_movie_new_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then iterate through the values of the dict number_of_ratings_per_movie_dict\n",
    "for val in number_of_ratings_per_movie_dict.values():\n",
    "    number_of_ratings_per_movie_new_indices.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create the rating matrix\n",
    "def create_the_rating_matrix(movies_df, num_movies, num_users):\n",
    "    full_ratings_mat = np.empty(shape=(num_users+1, num_movies))\n",
    "    full_ratings_mat.fill(np.nan)\n",
    "    #iterate through the movies_df\n",
    "    for index, row in ratings_df.iterrows():\n",
    "        new_movie_id = int(get_new_movie_id(row['movieId']))\n",
    "        user_id = int(row['userId'])\n",
    "        full_ratings_mat[user_id][new_movie_id] = row['rating']\n",
    "    full_ratings_mat=full_ratings_mat[1:]\n",
    "        \n",
    "    return full_ratings_mat\n",
    "    \n",
    "\n",
    "ratings_matrix = create_the_rating_matrix(movies_df, num_movies, num_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ratings_matrix = ratings_matrix[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.936e+03, 5.230e+02, 1.430e+02, 7.200e+01, 3.000e+01, 1.800e+01,\n",
       "        1.200e+01, 3.000e+00, 2.000e+00, 3.000e+00]),\n",
       " array([  0. ,  32.9,  65.8,  98.7, 131.6, 164.5, 197.4, 230.3, 263.2,\n",
       "        296.1, 329. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(number_of_ratings_per_movie_new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2. Plot the number of movies rated by each user \n",
    "\"\"\"\n",
    "number_of_movies_rated_by_each_user = []\n",
    "\n",
    "#set all the userID(s) number of mvoies rated to 0\n",
    "for user_id in range(1, 611):\n",
    "    number_of_movies_rated_by_each_user.append(0)\n",
    "\n",
    "for index, row in ratings_df.iterrows():\n",
    "    number_of_movies_rated_by_each_user[int(row['userId'])-1]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([520.,  54.,  15.,  12.,   5.,   0.,   1.,   1.,   0.,   2.]),\n",
       " array([  20. ,  287.8,  555.6,  823.4, 1091.2, 1359. , 1626.8, 1894.6,\n",
       "        2162.4, 2430.2, 2698. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADrhJREFUeJzt3V2MnFd9x/HvrzFJK0DYSbaWZZtuKJaq3BCsVeoKhFqihiRUdZAABVWNlVryTZBAtGpNuSiVepFUKmkjVZHcJqqDKCHiRbEgLbgmCPUigQ0E560hS5ootpzYkBBACNrAvxdzlg6u1zu7O8t4Tr8faTTnOc+Zec7fz/i3s2deNlWFJKlfvzTpCUiS1pdBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SerchklPAODiiy+u2dnZSU9DkqbKgw8++O2qmllu3DkR9LOzs8zPz096GpI0VZI8M8o4l24kqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalz58QnY9didv/nJnbsp296+8SOLUmj8hm9JHXOoJekzhn0ktS5kYI+ydNJHk7yUJL51ndhksNJnmzXm1p/ktyaZCHJ0SQ717MASdLZreQZ/e9U1WVVNde29wNHqmoHcKRtA1wN7GiXfcBt45qsJGnl1rJ0sxs42NoHgWuH+u+sgfuBjUm2rOE4kqQ1GDXoC/hCkgeT7Gt9m6vqRGs/B2xu7a3As0O3Pdb6JEkTMOr76N9cVceT/CpwOMl/DO+sqkpSKzlw+4GxD+C1r33tSm4qSVqBkZ7RV9Xxdn0S+AxwOfD84pJMuz7Zhh8Htg/dfFvrO/0+D1TVXFXNzcws+ycPJUmrtGzQJ3llklcvtoErgUeAQ8CeNmwPcE9rHwKub+++2QW8NLTEI0n6BRtl6WYz8Jkki+P/uar+NclXgbuT7AWeAd7dxt8LXAMsAD8Ebhj7rCVJI1s26KvqKeANZ+j/DnDFGfoLuHEss5MkrZmfjJWkzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMjB32S85J8Pcln2/YlSR5IspDkE0nOb/0XtO2Ftn92faYuSRrFSp7Rvw94fGj7ZuCWqno98CKwt/XvBV5s/be0cZKkCRkp6JNsA94O/GPbDvBW4JNtyEHg2tbe3bZp+69o4yVJEzDqM/q/Bf4U+Gnbvgj4blW93LaPAVtbeyvwLEDb/1IbL0magGWDPsnvASer6sFxHjjJviTzSeZPnTo1zruWJA0Z5Rn9m4DfT/I0cBeDJZu/AzYm2dDGbAOOt/ZxYDtA2/8a4Dun32lVHaiquaqam5mZWVMRkqSlLRv0VfXBqtpWVbPAdcAXq+oPgPuAd7Zhe4B7WvtQ26bt/2JV1VhnLUka2VreR/9nwAeSLDBYg7+99d8OXNT6PwDsX9sUJUlrsWH5If+rqr4EfKm1nwIuP8OYHwHvGsPcJElj4CdjJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknq3LJBn+SXk3wlyTeSPJrkL1v/JUkeSLKQ5BNJzm/9F7TthbZ/dn1LkCSdzSjP6H8MvLWq3gBcBlyVZBdwM3BLVb0eeBHY28bvBV5s/be0cZKkCVk26GvgB23zFe1SwFuBT7b+g8C1rb27bdP2X5EkY5uxJGlFRlqjT3JekoeAk8Bh4FvAd6vq5TbkGLC1tbcCzwK0/S8BF53hPvclmU8yf+rUqbVVIUla0khBX1U/qarLgG3A5cBvrPXAVXWgquaqam5mZmatdydJWsKK3nVTVd8F7gN+C9iYZEPbtQ043trHge0Abf9rgO+MZbaSpBUb5V03M0k2tvavAL8LPM4g8N/Zhu0B7mntQ22btv+LVVXjnLQkaXQblh/CFuBgkvMY/GC4u6o+m+Qx4K4kfwV8Hbi9jb8d+GiSBeAF4Lp1mLckaUTLBn1VHQXeeIb+pxis15/e/yPgXWOZnSRpzfxkrCR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SercskGfZHuS+5I8luTRJO9r/RcmOZzkyXa9qfUnya1JFpIcTbJzvYuQJC1tlGf0LwN/XFWXAruAG5NcCuwHjlTVDuBI2wa4GtjRLvuA28Y+a0nSyJYN+qo6UVVfa+3vA48DW4HdwME27CBwbWvvBu6sgfuBjUm2jH3mkqSRrGiNPsks8EbgAWBzVZ1ou54DNrf2VuDZoZsda32SpAkYOeiTvAr4FPD+qvre8L6qKqBWcuAk+5LMJ5k/derUSm4qSVqBkYI+ySsYhPzHqurTrfv5xSWZdn2y9R8Htg/dfFvr+zlVdaCq5qpqbmZmZrXzlyQtY5R33QS4HXi8qj4ytOsQsKe19wD3DPVf3959swt4aWiJR5L0C7ZhhDFvAv4QeDjJQ63vz4GbgLuT7AWeAd7d9t0LXAMsAD8EbhjrjCVJK7Js0FfVvwNZYvcVZxhfwI1rnJckaUz8ZKwkdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ1bNuiT3JHkZJJHhvouTHI4yZPtelPrT5JbkywkOZpk53pOXpK0vFGe0f8TcNVpffuBI1W1AzjStgGuBna0yz7gtvFMU5K0WssGfVV9GXjhtO7dwMHWPghcO9R/Zw3cD2xMsmVck5Ukrdxq1+g3V9WJ1n4O2NzaW4Fnh8Yda32SpAlZ84uxVVVArfR2SfYlmU8yf+rUqbVOQ5K0hNUG/fOLSzLt+mTrPw5sHxq3rfX9H1V1oKrmqmpuZmZmldOQJC1ntUF/CNjT2nuAe4b6r2/vvtkFvDS0xCNJmoANyw1I8nHgt4GLkxwD/gK4Cbg7yV7gGeDdbfi9wDXAAvBD4IZ1mLMkaQWWDfqqes8Su644w9gCblzrpCRJ4+MnYyWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjq37LdXammz+z83keM+fdPbJ3JcSdPJZ/SS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zu+jn0KT+h588LvwpWlk0GtF/GMr0vRZl6WbJFcleSLJQpL963EMSdJoxh70Sc4D/h64GrgUeE+SS8d9HEnSaNZj6eZyYKGqngJIchewG3hsHY6l/ydcMpJWbz2Cfivw7ND2MeA31+E4Utcm+aL7pEzqB2vvb3CY2IuxSfYB+9rmD5I8scK7uBj49nhndc6xxgnLzWO5m3O6xjEYW31j+vdeD+t2DtdY86+NMmg9gv44sH1oe1vr+zlVdQA4sNqDJJmvqrnV3n4aWGMfeq+x9/pg+mtcj3fdfBXYkeSSJOcD1wGH1uE4kqQRjP0ZfVW9nOS9wOeB84A7qurRcR9HkjSadVmjr6p7gXvX476HrHrZZ4pYYx96r7H3+mDKa0xVTXoOkqR15JeaSVLnpjLoe/mKhSRPJ3k4yUNJ5lvfhUkOJ3myXW9q/Ulya6v5aJKdk539mSW5I8nJJI8M9a24piR72vgnk+yZRC1LWaLGDyc53s7lQ0muGdr3wVbjE0neNtR/zj6Ok2xPcl+Sx5I8muR9rb+Lc3mW+ro6jz9TVVN1YfAC77eA1wHnA98ALp30vFZZy9PAxaf1/TWwv7X3Aze39jXAvwABdgEPTHr+S9T0FmAn8MhqawIuBJ5q15tae9Oka1umxg8Df3KGsZe2x+gFwCXtsXveuf44BrYAO1v71cA3Wy1dnMuz1NfVeVy8TOMz+p99xUJV/Rew+BULvdgNHGztg8C1Q/131sD9wMYkWyYxwbOpqi8DL5zWvdKa3gYcrqoXqupF4DBw1frPfjRL1LiU3cBdVfXjqvpPYIHBY/icfhxX1Ymq+lprfx94nMGn3rs4l2epbylTeR4XTWPQn+krFs52gs5lBXwhyYPtk8IAm6vqRGs/B2xu7Wmue6U1TWut723LFncsLmnQQY1JZoE3Ag/Q4bk8rT7o8DxOY9D35M1VtZPBN33emOQtwztr8DtjV2+L6rGm5jbg14HLgBPA30x2OuOR5FXAp4D3V9X3hvf1cC7PUF+X53Eag36kr1iYBlV1vF2fBD7D4NfA5xeXZNr1yTZ8muteaU1TV2tVPV9VP6mqnwL/wOBcwhTXmOQVDELwY1X16dbdzbk8U309nkeYzqDv4isWkrwyyasX28CVwCMMall8Z8Ie4J7WPgRc397dsAt4aehX6HPdSmv6PHBlkk3tV+crW98567TXS97B4FzCoMbrklyQ5BJgB/AVzvHHcZIAtwOPV9VHhnZ1cS6Xqq+38/gzk341eDUXBq/wf5PBq90fmvR8VlnD6xi8Qv8N4NHFOoCLgCPAk8C/ARe2/jD4gy7fAh4G5iZdwxJ1fZzBr7z/zWC9cu9qagL+iMELXgvADZOua4QaP9pqOMrgP/qWofEfajU+AVw9DY9j4M0MlmWOAg+1yzW9nMuz1NfVeVy8+MlYSercNC7dSJJWwKCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalz/wPDVRaA58m7dAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the movies_rated_by_each_user\n",
    "plt.hist(number_of_movies_rated_by_each_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Forrest Gump (1994)',\n",
       " 'Shawshank Redemption, The (1994)',\n",
       " 'Pulp Fiction (1994)',\n",
       " 'Silence of the Lambs, The (1991)',\n",
       " 'Matrix, The (1999)',\n",
       " 'Star Wars: Episode IV - A New Hope (1977)',\n",
       " 'Jurassic Park (1993)',\n",
       " 'Braveheart (1995)',\n",
       " 'Terminator 2: Judgment Day (1991)',\n",
       " \"Schindler's List (1993)\",\n",
       " 'Fight Club (1999)',\n",
       " 'Toy Story (1995)',\n",
       " 'Star Wars: Episode V - The Empire Strikes Back (1980)',\n",
       " 'American Beauty (1999)',\n",
       " 'Usual Suspects, The (1995)',\n",
       " 'Seven (a.k.a. Se7en) (1995)',\n",
       " 'Independence Day (a.k.a. ID4) (1996)',\n",
       " 'Apollo 13 (1995)',\n",
       " 'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)',\n",
       " 'Lord of the Rings: The Fellowship of the Ring, The (2001)',\n",
       " 'Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       " 'Godfather, The (1972)',\n",
       " 'Fugitive, The (1993)',\n",
       " 'Batman (1989)',\n",
       " 'Lord of the Rings: The Two Towers, The (2002)',\n",
       " 'Saving Private Ryan (1998)',\n",
       " 'Lord of the Rings: The Return of the King, The (2003)',\n",
       " 'Aladdin (1992)',\n",
       " 'Fargo (1996)',\n",
       " 'Sixth Sense, The (1999)',\n",
       " 'True Lies (1994)',\n",
       " 'Twelve Monkeys (a.k.a. 12 Monkeys) (1995)',\n",
       " 'Lion King, The (1994)',\n",
       " 'Back to the Future (1985)',\n",
       " 'Speed (1994)',\n",
       " 'Shrek (2001)',\n",
       " 'Gladiator (2000)',\n",
       " 'Men in Black (a.k.a. MIB) (1997)',\n",
       " 'Dances with Wolves (1990)',\n",
       " 'Mission: Impossible (1996)',\n",
       " 'Ace Ventura: Pet Detective (1994)',\n",
       " 'Memento (2000)',\n",
       " 'Mask, The (1994)',\n",
       " 'Dark Knight, The (2008)',\n",
       " 'Pirates of the Caribbean: The Curse of the Black Pearl (2003)',\n",
       " 'Alien (1979)',\n",
       " 'Beauty and the Beast (1991)',\n",
       " 'Die Hard (1988)',\n",
       " 'Mrs. Doubtfire (1993)',\n",
       " 'Die Hard: With a Vengeance (1995)',\n",
       " 'Inception (2010)',\n",
       " 'Groundhog Day (1993)',\n",
       " 'Princess Bride, The (1987)',\n",
       " 'Finding Nemo (2003)',\n",
       " 'Good Will Hunting (1997)',\n",
       " 'Star Wars: Episode I - The Phantom Menace (1999)',\n",
       " 'Titanic (1997)',\n",
       " 'Indiana Jones and the Last Crusade (1989)',\n",
       " 'Stargate (1994)',\n",
       " 'Batman Forever (1995)',\n",
       " 'Monty Python and the Holy Grail (1975)',\n",
       " 'Pretty Woman (1990)',\n",
       " 'X-Men (2000)',\n",
       " \"One Flew Over the Cuckoo's Nest (1975)\",\n",
       " 'Léon: The Professional (a.k.a. The Professional) (Léon) (1994)',\n",
       " 'Dumb & Dumber (Dumb and Dumber) (1994)',\n",
       " 'Monsters, Inc. (2001)',\n",
       " 'GoldenEye (1995)',\n",
       " 'Eternal Sunshine of the Spotless Mind (2004)',\n",
       " 'Kill Bill: Vol. 1 (2003)',\n",
       " 'Terminator, The (1984)',\n",
       " 'Reservoir Dogs (1992)',\n",
       " 'American History X (1998)',\n",
       " 'Godfather: Part II, The (1974)',\n",
       " 'Babe (1995)',\n",
       " 'Goodfellas (1990)',\n",
       " 'Aliens (1986)',\n",
       " 'Incredibles, The (2004)',\n",
       " 'Truman Show, The (1998)',\n",
       " 'Blade Runner (1982)',\n",
       " 'Beautiful Mind, A (2001)',\n",
       " 'Twister (1996)',\n",
       " 'Spider-Man (2002)',\n",
       " 'E.T. the Extra-Terrestrial (1982)',\n",
       " 'Austin Powers: The Spy Who Shagged Me (1999)',\n",
       " 'Rock, The (1996)',\n",
       " 'Minority Report (2002)',\n",
       " \"Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\",\n",
       " 'Ghostbusters (a.k.a. Ghost Busters) (1984)',\n",
       " 'Clockwork Orange, A (1971)',\n",
       " \"Ocean's Eleven (2001)\",\n",
       " 'Willy Wonka & the Chocolate Factory (1971)',\n",
       " 'Batman Begins (2005)',\n",
       " 'Fifth Element, The (1997)',\n",
       " 'Home Alone (1990)',\n",
       " 'Catch Me If You Can (2002)',\n",
       " 'Ghost (1990)',\n",
       " 'Waterworld (1995)',\n",
       " 'Breakfast Club, The (1985)',\n",
       " 'Bourne Identity, The (2002)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q3. Number of ratings per movie ... get the 100 most popular ones by most ratings criteria\n",
    "\"\"\"\n",
    "hundred_most_popular_by_id = sorted(number_of_ratings_per_movie_dict.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)[0:100]\n",
    "hundred_most_popularity_by_name =  []\n",
    "\n",
    "for movie_id, num_of_ratings in hundred_most_popular_by_id:\n",
    "    movie_name = get_movie_name_by_id(movie_id)\n",
    "    hundred_most_popularity_by_name.append(movie_name)\n",
    "    \n",
    "hundred_most_popularity_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to compute the accuracy \n",
    "#1. uses Root Mean Squared Error\n",
    "def get_rmse(predicted_rating_matrix, test_rating_matrix):\n",
    "    num_users = test_rating_matrix.shape[0]\n",
    "    num_movies = test_rating_matrix.shape[1]\n",
    "    \n",
    "    error = 0.0\n",
    "    \n",
    "    num_calcs = 0\n",
    "    \n",
    "    for user_id in range(num_users):\n",
    "        for movie_id in range(num_movies):\n",
    "            if np.isnan(test_rating_matrix[user_id][movie_id])==False and np.isnan(predicted_rating_matrix[user_id][movie_id])==False:\n",
    "                diff = abs(predicted_rating_matrix[user_id][movie_id]-test_rating_matrix[user_id][movie_id])\n",
    "#                 print(diff)\n",
    "                error = error + diff*diff\n",
    "                num_calcs+=1\n",
    "#     print(\"Number Calculated - {}\".format(num_calcs))\n",
    "    return np.sqrt(error)\n",
    "\n",
    "#2. uses Mean Absolute Error\n",
    "def get_mae(predicted_rating_matrix, test_rating_matrix):\n",
    "    num_users = test_rating_matrix.shape[0]\n",
    "    num_movies = test_rating_matrix.shape[1]\n",
    "    \n",
    "    error = 0.0\n",
    "    \n",
    "    num_calcs = 0\n",
    "    \n",
    "    for user_id in range(num_users):\n",
    "        for movie_id in range(num_movies):\n",
    "            if np.isnan(test_rating_matrix[user_id][movie_id])==False and np.isnan(predicted_rating_matrix[user_id][movie_id])==False:\n",
    "                diff = abs(predicted_rating_matrix[user_id][movie_id]-test_rating_matrix[user_id][movie_id])\n",
    "#                 print(diff)\n",
    "                error = error + diff\n",
    "                num_calcs+=1\n",
    "#     print(\"Number Calculated - {}\".format(num_calcs))\n",
    "    return error\n",
    "\n",
    "#function to get the mean center of the rating matrix\n",
    "def get_mean_centered(input_rating_matrix):\n",
    "    num_users = input_rating_matrix.shape[0]\n",
    "    mean_centered_rating_matrix = np.empty(shape=input_rating_matrix.shape)\n",
    "    for user_id in range(num_users):\n",
    "        mean_centered_rating_matrix[user_id] = input_rating_matrix[user_id]-np.nanmean(input_rating_matrix[user_id])\n",
    "    return mean_centered_rating_matrix\n",
    "\n",
    "# function to split the dataset intro train, test\n",
    "def split_the_dset(input_rating_matrix, train_ratio=70.0, mean_center=False):\n",
    "    #sample from a uniform distribution to prepare a \n",
    "    np.random.seed(0) ;\n",
    "    mask = np.random.uniform(low=0.0, high=100.0, size=input_rating_matrix.shape)\n",
    "    #set the curoff at train ratio\n",
    "    mask = mask<=train_ratio\n",
    "    \n",
    "    train_rating_matrix = np.empty(shape=input_rating_matrix.shape)\n",
    "    train_rating_matrix.fill(np.nan)\n",
    "\n",
    "    test_rating_matrix = np.empty(shape=input_rating_matrix.shape)\n",
    "    test_rating_matrix.fill(np.nan)\n",
    "\n",
    "    #loop through the elments of the input training matrix\n",
    "    for user in range(input_rating_matrix.shape[0]):\n",
    "        for item in range(input_rating_matrix.shape[1]):\n",
    "            if mask[user][item]==True and input_rating_matrix[user][item]!=np.nan:\n",
    "                train_rating_matrix[user][item] = input_rating_matrix[user][item]\n",
    "            elif mask[user][item]==False and input_rating_matrix[user][item]!=np.nan:\n",
    "                test_rating_matrix[user][item] = input_rating_matrix[user][item]\n",
    "\n",
    "    return train_rating_matrix, test_rating_matrix\n",
    "\n",
    "        \n",
    "\n",
    "#this function returns a dict where key is the id of the user and the value is  a list of rated movie tuples ... \n",
    "#so a list of (movie_id, rating_for_movie)\n",
    "def get_compress_training_rating_matrix(train_rating_matrix):\n",
    "    num_users = train_rating_matrix.shape[0]\n",
    "    num_movies = train_rating_matrix.shape[1]\n",
    "    compressed_train_rating_matrix = {}\n",
    "    for user_num in range(num_users):\n",
    "        compressed_train_rating_matrix[user_num] = {}\n",
    "    for user_id in range(num_users):\n",
    "        for movie_id in range(num_movies):\n",
    "            if not np.isnan(train_rating_matrix[user_id][movie_id]):\n",
    "                compressed_train_rating_matrix[user_id][movie_id] = train_rating_matrix[user_id][movie_id]\n",
    "    return compressed_train_rating_matrix\n",
    "\n",
    "#function to get the pearson similairty from two users \n",
    "def get_pearson_similarity(user_u, user_v):\n",
    "    if len(user_u)==0 or len(user_v)==0: return np.nan\n",
    "    #calculate the mean of the ratings of user_u and user_v\n",
    "    mean_u = np.nanmean(user_u)\n",
    "    mean_v = np.nanmean(user_v)\n",
    "\n",
    "    #now go through the intersection of the user_u and user_v\n",
    "    num = 0.0\n",
    "    dem1 = 0.0\n",
    "    dem2 = 0.0\n",
    "    for i in range(user_u.shape[0]):\n",
    "        num = num + (user_u[i]-mean_u)*(user_v[i]-mean_v)\n",
    "        dem1 = dem1 + np.square(user_u[i]-mean_u)\n",
    "        dem2 = dem2 +np.square(user_v[i]-mean_v)\n",
    "#     print(num, dem1, dem2)\n",
    "    return num/(np.sqrt(dem1)*np.sqrt(dem2))\n",
    "\n",
    "#function to get the cosine similairty from two users \n",
    "def get_cosine_similarity(user_u, user_v):\n",
    "    if len(user_u)==0 or len(user_v)==0: return np.nan\n",
    "    num = 0.0\n",
    "    dem1 = 0.0\n",
    "    dem2 = 0.0\n",
    "    for i in range(user_u.shape[0]):\n",
    "        num = num + user_u[i]*user_v[i]\n",
    "        dem1 = dem1 + np.square(user_u[i])\n",
    "        dem2 = dem2 + np.square(user_v[i])\n",
    "#     print(num, dem1, dem2)\n",
    "    return num/(np.sqrt(dem1)*np.sqrt(dem2))\n",
    "\n",
    "#function to get pearson similarity from compressed form of the two sets of the user(s)\n",
    "def get_pearson_similarity_compressed(user_u, user_v):\n",
    "    #user_u and user_v are dicts themselves\n",
    "    #iterate through the user_u keys\n",
    "    rated_by_both = [[], []]\n",
    "    for item_id in user_u.keys():\n",
    "        #check if that item is rated by user_v\n",
    "        if item_id in user_v.keys():\n",
    "            rated_by_both[0].append(user_u[item_id])\n",
    "            rated_by_both[1].append(user_v[item_id])\n",
    "    #store the rated_by_both list as a numpy array and then call the get_pearson_similarity function on it\n",
    "    rated_by_both_np = np.array(rated_by_both)\n",
    "   \n",
    "    return get_pearson_similarity(rated_by_both_np[0], rated_by_both_np[1])\n",
    "\n",
    "#function to get pearson similarity from compressed form of the two sets of the user(s)\n",
    "def get_cosine_similarity_compressed(user_u, user_v):\n",
    "    #user_u and user_v are dicts themselves\n",
    "    #iterate through the user_u keys\n",
    "    rated_by_both = [[], []]\n",
    "    for item_id in user_u.keys():\n",
    "        #check if that item is rated by user_v\n",
    "        if item_id in user_v.keys():\n",
    "            rated_by_both[0].append(user_u[item_id])\n",
    "            rated_by_both[1].append(user_v[item_id])\n",
    "    #store the rated_by_both list as a numpy array and then call the get_pearson_similarity function on it\n",
    "    rated_by_both_np = np.array(rated_by_both)\n",
    "    \n",
    "    return get_cosine_similarity(rated_by_both_np[0], rated_by_both_np[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0000000000000002, 0.7543365091413573)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell for testing the above functions\n",
    "\"\"\"\n",
    "# sample_rm = np.array([[1, 2,np.nan], [4,4, 10]])\n",
    "# get_mean_centered(sample_rm)\n",
    "\"\"\"\n",
    "Get the mean centered rating matrix using the get_mean_centered function\n",
    "\"\"\"\n",
    "mean_centered_ratings_matrix = get_mean_centered(ratings_matrix)\n",
    "rm = {}\n",
    "rm[0] = {614: 2.0, 616:2.0, 618:1.0}\n",
    "rm[1] = {614: 2.0, 616:2.0, 618:5.0}\n",
    "\n",
    "get_pearson_similarity_compressed(rm[0], rm[1]), get_cosine_similarity_compressed(rm[0], rm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function returns number of non-nan elements in matrix\n",
    "def get_num_non_nan(mat):\n",
    "    rows = mat.shape[0]\n",
    "    cols = mat.shape[1]\n",
    "    res =0\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            if np.isnan(mat[row][col])==False:\n",
    "                res+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rating_matrix, test_rating_matrix = split_the_dset(ratings_matrix)\n",
    "mean_centered_train_rating_matrix, mean_centered_test_rating_matrix = split_the_dset(mean_centered_ratings_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70704, 30132)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_non_nan(train_rating_matrix), get_num_non_nan(test_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_train_rating_matrix = get_compress_training_rating_matrix(train_rating_matrix)\n",
    "mean_centered_compressed_train_rating_matrix = get_compress_training_rating_matrix(mean_centered_train_rating_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to get pairwise similarity from the compressed train rating matrix\n",
    "params:\n",
    "---pearson: uses pearson similarity coefficient if True ... cosine similarity if False\n",
    "\"\"\"\n",
    "def get_user_similarity_matrix(compressed_train_rating_matrix,  pearson = True, chk_interval=300):\n",
    "    #make a similarity matrix of size [user, user]\n",
    "    num_users = len(compressed_train_rating_matrix)\n",
    "#     print(num_users)\n",
    "    uu_mat = np.empty(shape=(num_users, num_users))\n",
    "    uu_mat.fill(0)\n",
    "    #get similarity of all the users\n",
    "\n",
    "    for u in range(num_users):\n",
    "        if u%chk_interval==0:\n",
    "            print(u)\n",
    "        for v in range(num_users):\n",
    "            I_u = compressed_train_rating_matrix[u]\n",
    "            I_v = compressed_train_rating_matrix[v]\n",
    "#             print(I_u)\n",
    "            if pearson==True:\n",
    "                uu_mat[u][v] = get_pearson_similarity_compressed(I_u, I_v)\n",
    "            else:\n",
    "                uu_mat[u][v] = get_cosine_similarity_compressed(I_u, I_v)\n",
    "    return uu_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/.local/lib/python3.6/site-packages/ipykernel_launcher.py:102: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "600\n",
      "0\n",
      "300\n",
      "600\n",
      "0\n",
      "300\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "#pearson uu similarity matrix\n",
    "pearson_uu_mat = get_user_similarity_matrix(compressed_train_rating_matrix, pearson=True)\n",
    "#pearson uu similarity matrix using mean centering\n",
    "mean_centered_pearson_uu_mat = get_user_similarity_matrix(mean_centered_compressed_train_rating_matrix, pearson=True)\n",
    "#cosine uu similarity matrix\n",
    "cosine_uu_mat = get_user_similarity_matrix(compressed_train_rating_matrix, pearson=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for prediction\n",
    "\"\"\"\n",
    "def get_top_k(uu_mat, train_rating_matrix, user_id, movie_id, k):\n",
    "    #iterate through a users row and get the column ids of the k most similar\n",
    "    num_users = uu_mat.shape[0]\n",
    "    top_k = {}#key is the other users_id and the value is (similarity of this user with other, rating of movie_id by other)\n",
    "    for other_id in range(num_users):\n",
    "        #check if user and other have a similarity computed and also whether other has rated for this item\n",
    "        if np.isnan(uu_mat[user_id][other_id])==False and user_id!=other_id and np.isnan(train_rating_matrix[other_id][movie_id])==False:\n",
    "            top_k[other_id] = (uu_mat[user_id][other_id], train_rating_matrix[other_id][movie_id])\n",
    "    #sort the top_k dict according to most similarity that is the values of top_k dict\n",
    "    \n",
    "    top_k = sorted(top_k.items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
    "\n",
    "    return collections.OrderedDict(top_k)\n",
    "\n",
    "def get_prediction(uu_mat, train_rating_matrix, user_id, movie_id, k, mean_centered=False, full_train_rating_matrix=None):\n",
    "    top_k = get_top_k(uu_mat, train_rating_matrix, user_id, movie_id, k)\n",
    "\n",
    "#     print(\"\\n\")\n",
    "    #if no users are matching .... then return 2.5 randomly\n",
    "    if len(top_k)==0: return 2.5\n",
    "    #if there are top_k users\n",
    "    num = 0.0\n",
    "    den = 0.0\n",
    "    \n",
    "    num_counted = 0\n",
    "#     print(type(top_k))\n",
    "    for item in top_k.values():\n",
    "#         print(item)\n",
    "        sim = item[0]\n",
    "        rating = item[1]\n",
    "        if num_counted==k:break\n",
    "        num = num + sim*rating\n",
    "        den = den + abs(sim)\n",
    "        num_counted+=1\n",
    "    \n",
    "    if mean_centered==False:\n",
    "        return num/den\n",
    "    else:\n",
    "        mean_u = np.nanmean(full_train_rating_matrix[user_id])\n",
    "#         print(\"mean \", mean_u, mean_u + (num/den))\n",
    "        return  mean_u + (num/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_whole(uu_mat, train_rating_matrix, test_rating_matrix, K, mean_centered=False, full_train_rating_matrix=None):\n",
    "    num_users = test_rating_matrix.shape[0]\n",
    "    num_movies = test_rating_matrix.shape[1]\n",
    "    \n",
    "    predicted_rating_matrix = np.empty(test_rating_matrix.shape)\n",
    "    predicted_rating_matrix.fill(np.nan)\n",
    "    \n",
    "    for user_id in range(num_users):\n",
    "        for movie_id in range(num_movies):\n",
    "            if np.isnan(test_rating_matrix[user_id][movie_id])==False:\n",
    "                predicted_rating_matrix[user_id][movie_id] = get_prediction(uu_mat, train_rating_matrix, user_id, movie_id, K, mean_centered=mean_centered, full_train_rating_matrix=full_train_rating_matrix)\n",
    "    #returns the prediction matrix\n",
    "    return predicted_rating_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/.local/lib/python3.6/site-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1; mae=30511.0, rmse=243.19539469323837\n",
      "K=2; mae=28079.126059284255, rmse=225.90605662966007\n",
      "K=3; mae=27388.631296646654, rmse=223.78881967209313\n",
      "K=4; mae=27193.758071667242, rmse=225.0953036906732\n",
      "K=5; mae=27179.67020152852, rmse=226.79170811249145\n",
      "K=6; mae=27352.477471578164, rmse=229.60416545822423\n",
      "K=7; mae=27562.03441574602, rmse=232.56760957930277\n",
      "K=8; mae=27827.043636807848, rmse=235.50866627513025\n",
      "K=9; mae=28119.357504569336, rmse=238.22528393725722\n",
      "K=10; mae=28432.39782708916, rmse=240.96689672513514\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q4. Do the user-neighborhood based predictions\n",
    "    Find the appropriate K\n",
    "\"\"\"\n",
    "\n",
    "#1. Prediction using pearson similarity without mean centering\n",
    "results_pearson = {}\n",
    "for k in range(1, 11):\n",
    "    pred_mat_uu_pearson = predict_whole(pearson_uu_mat, train_rating_matrix, test_rating_matrix, K=k)\n",
    "    mae = get_mae(pred_mat_uu_pearson, test_rating_matrix)\n",
    "    rmse = get_rmse(pred_mat_uu_pearson, test_rating_matrix)\n",
    "    print(\"K={}; mae={}, rmse={}\".format(k, mae, rmse))\n",
    "    results_pearson[k] = (mae, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/.local/lib/python3.6/site-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1; mae=27645.050306667807, rmse=205.34904657429067\n",
      "K=2; mae=24528.489619426466, rmse=181.7631537121451\n",
      "K=3; mae=23277.70735743458, rmse=173.35945980674936\n"
     ]
    }
   ],
   "source": [
    "#2. Prediction using pearson similarity without mean centering\n",
    "results_pearson_with_mean_centering = {}\n",
    "for k in range(1, 11):\n",
    "    pred_mat_uu_pearson_mean_centering = predict_whole(mean_centered_pearson_uu_mat, mean_centered_train_rating_matrix, test_rating_matrix, K=k, mean_centered=True, full_train_rating_matrix=train_rating_matrix)\n",
    "    mae = get_mae(pred_mat_uu_pearson_mean_centering, test_rating_matrix)\n",
    "    rmse = get_rmse(pred_mat_uu_pearson_mean_centering, test_rating_matrix)\n",
    "    print(\"K={}; mae={}, rmse={}\".format(k, mae, rmse))\n",
    "    results_pearson_with_mean_centering[k] = (mae, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Prediction using cosine similarity without mean centering\n",
    "results_cosine = {}\n",
    "for k in range(1, 11):\n",
    "    pred_mat_uu_cosine = predict_whole(uu_mat=sine_uu_mat_uu_mat, train_rating_matrix, test_rating_matrix, K=k)\n",
    "    mae = get_mae(pred_mat_uu_cosine, test_rating_matrix)\n",
    "    rmse = get_rmse(pred_mat_uu_cosine, test_rating_matrix)\n",
    "    print(\"K={}; mae={}, rmse={}\".format(k, mae, rmse))\n",
    "    results_cosine[k] = (mae, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
